{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yourusername/mlsp-cocktail-party-problem/blob/main/notebooks/bilstm_colab_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUfHagBCz7rJ"
   },
   "source": [
    "# BiLSTM Source Separation Training on Google Colab\n",
    "\n",
    "This notebook trains a BiLSTM-based audio source separation model on the LibriMix dataset using Google Colab's GPU.\n",
    "\n",
    "## Setup Steps:\n",
    "1. Clone the project repository\n",
    "2. Install dependencies\n",
    "3. Download LibriMix dataset (16kHz, 2-source)\n",
    "4. Configure model and training hyperparameters\n",
    "5. Train the model with GPU acceleration\n",
    "6. Monitor training with logs and checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup: Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "# check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clone-repo-cmd"
   },
   "outputs": [],
   "source": [
    "# clone the repository\n",
    "import os\n",
    "os.chdir('/content')\n",
    "\n",
    "# NOTE: Replace with your actual GitHub repository URL\n",
    "!git clone https://github.com/yourusername/mlsp-cocktail-party-problem.git\n",
    "os.chdir('/content/mlsp-cocktail-party-problem')\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# install dependencies from requirements.txt\n",
    "!pip install -q -r requirements.txt\n",
    "print(\"Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset-setup"
   },
   "source": [
    "## 2. Dataset Setup\n",
    "\n",
    "### Option A: Download LibriMix (Recommended)\n",
    "The download takes ~30-45 minutes. LibriMix is ~50GB (compressed), extracting to ~100GB.\n",
    "\n",
    "### Option B: Use Existing LibriMix\n",
    "If you've already downloaded LibriMix, mount your Google Drive and point to its location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "download-librimix"
   },
   "outputs": [],
   "source": [
    "# Option A: Download LibriMix from HuggingFace Datasets\n",
    "# This will download the 16kHz, 2-source dataset (~50GB compressed)\n",
    "\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path('/content/mlsp-cocktail-party-problem/data/Libri2Mix')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Downloading LibriMix dataset from HuggingFace...\")\n",
    "print(\"This will take 30-45 minutes depending on connection speed.\")\n",
    "print(\"You can monitor progress in the output below.\\n\")\n",
    "\n",
    "# Load the LibriMix dataset (16kHz variant)\n",
    "# Available splits: train-100, dev, test\n",
    "try:\n",
    "    # Download training set\n",
    "    ds_train = load_dataset(\n",
    "        'JorisCos/LibriMix',\n",
    "        name='libri2mix_16k',\n",
    "        split='train-100',\n",
    "        cache_dir=str(data_dir)\n",
    "    )\n",
    "    print(f\"\\nTraining set downloaded: {len(ds_train)} samples\")\n",
    "    \n",
    "    # Download validation set\n",
    "    ds_val = load_dataset(\n",
    "        'JorisCos/LibriMix',\n",
    "        name='libri2mix_16k',\n",
    "        split='dev',\n",
    "        cache_dir=str(data_dir)\n",
    "    )\n",
    "    print(f\"Validation set downloaded: {len(ds_val)} samples\")\n",
    "    \n",
    "    # Download test set\n",
    "    ds_test = load_dataset(\n",
    "        'JorisCos/LibriMix',\n",
    "        name='libri2mix_16k',\n",
    "        split='test',\n",
    "        cache_dir=str(data_dir)\n",
    "    )\n",
    "    print(f\"Test set downloaded: {len(ds_test)} samples\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Note: If download fails, you can mount Google Drive and use existing LibriMix:\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mount-gdrive"
   },
   "outputs": [],
   "source": [
    "# Option B: Mount Google Drive if dataset already exists there\n",
    "from google.colab import drive\n",
    "\n",
    "try:\n",
    "    drive.mount('/content/gdrive')\n",
    "    print(\"Google Drive mounted successfully!\")\n",
    "    print(\"\\nIf you have LibriMix in Drive, symlink it:\")\n",
    "    print(\"/content/gdrive/My Drive/Datasets/Libri2Mix -> /content/mlsp-cocktail-party-problem/data/Libri2Mix\")\n",
    "except:\n",
    "    print(\"Google Drive mount failed. Using downloaded dataset instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training-config"
   },
   "source": [
    "## 3. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "verify-dataset"
   },
   "outputs": [],
   "source": [
    "# verify dataset is available\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "data_root = Path('/content/mlsp-cocktail-party-problem/data/Libri2Mix')\n",
    "config_data = Path('/content/mlsp-cocktail-party-problem/config/libri2mix_16k_2src.yaml')\n",
    "config_model = Path('/content/mlsp-cocktail-party-problem/config/bilstm.yaml')\n",
    "\n",
    "print(f\"Data root exists: {data_root.exists()}\")\n",
    "print(f\"Data config exists: {config_data.exists()}\")\n",
    "print(f\"Model config exists: {config_model.exists()}\")\n",
    "\n",
    "if data_root.exists():\n",
    "    print(f\"\\nDataset structure:\")\n",
    "    for item in sorted(data_root.iterdir()):\n",
    "        print(f\"  {item.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "config-display"
   },
   "outputs": [],
   "source": [
    "# display current configurations\n",
    "import yaml\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"DATASET CONFIG (libri2mix_16k_2src.yaml)\")\n",
    "print(\"=\" * 50)\n",
    "with open(config_data) as f:\n",
    "    dataset_config = yaml.safe_load(f)\n",
    "    print(yaml.dump(dataset_config, default_flow_style=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MODEL CONFIG (bilstm.yaml)\")\n",
    "print(\"=\" * 50)\n",
    "with open(config_model) as f:\n",
    "    model_config = yaml.safe_load(f)\n",
    "    print(yaml.dump(model_config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "modify-config"
   },
   "source": [
    "### Optional: Modify Training Configuration\n",
    "\n",
    "Adjust these settings if needed for your training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "custom-config"
   },
   "outputs": [],
   "source": [
    "# Optional: Create a custom config file for Colab-specific settings\n",
    "# You can modify these values before training\n",
    "\n",
    "import yaml\n",
    "\n",
    "# Create a Colab-optimized config (feel free to adjust)\n",
    "colab_config = {\n",
    "    'dataset': {\n",
    "        'sample_rate': 16000,\n",
    "        'n_src': 2,\n",
    "        'mode': 'min',\n",
    "        'mixture_type': 'mix_clean'\n",
    "    },\n",
    "    'run': {\n",
    "        'seed': 42,\n",
    "        'device': 'cuda'  # Use GPU on Colab\n",
    "    },\n",
    "    'model': {\n",
    "        'num_layers': 2,\n",
    "        'hidden_size': 512,\n",
    "        'dropout': 0.3,\n",
    "        'n_fft': 1024,\n",
    "        'hop_length': 256\n",
    "    },\n",
    "    'training': {\n",
    "        'epochs': 50,  # Reduce if short on time (set to 10-20 for quick testing)\n",
    "        'early_stopping_patience': 10,\n",
    "        'learning_rate': 3e-3,\n",
    "        'weight_decay': 1e-4,\n",
    "        'gradient_clip_norm': 5.0,\n",
    "        'scheduler': 'cosine',\n",
    "        'scheduler_params': {\n",
    "            'step': {'step_size': 10, 'gamma': 0.1},\n",
    "            'reduce_on_plateau': {'factor': 0.5, 'patience': 5},\n",
    "            'cosine': None\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# MODIFY THESE VALUES FOR YOUR TRAINING:\n",
    "EPOCHS = 50  # Set to 10-20 for quick test\n",
    "LEARNING_RATE = 3e-3\n",
    "HIDDEN_SIZE = 512  # Reduce to 256 if OOM\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "colab_config['training']['epochs'] = EPOCHS\n",
    "colab_config['training']['learning_rate'] = LEARNING_RATE\n",
    "colab_config['model']['hidden_size'] = HIDDEN_SIZE\n",
    "colab_config['model']['num_layers'] = NUM_LAYERS\n",
    "\n",
    "# Save custom config\n",
    "config_path = '/content/mlsp-cocktail-party-problem/config/bilstm_colab.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(colab_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"Colab config saved to: {config_path}\")\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Hidden Size: {HIDDEN_SIZE}\")\n",
    "print(f\"  Number of Layers: {NUM_LAYERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## 4. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "train"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('/content/mlsp-cocktail-party-problem')\n",
    "\n",
    "# Training command\n",
    "# NOTE: Update these paths if you've created a custom config\n",
    "train_cmd = [\n",
    "    'python', '-m', 'src.train.bilstm_train',\n",
    "    '--root-dir-data', 'data/Libri2Mix',\n",
    "    '--config-data', 'config/libri2mix_16k_2src.yaml',\n",
    "    '--config-model', 'config/bilstm_colab.yaml',  # Use custom Colab config\n",
    "    '--save-dir', 'output/models/bilstm_colab',\n",
    "    '--save-checkpoints',\n",
    "    '--save-every', '5',\n",
    "    '--log-level', 'INFO'\n",
    "]\n",
    "\n",
    "print(f\"Starting training...\")\n",
    "print(f\"Command: {' '.join(train_cmd)}\\n\")\n",
    "\n",
    "# Run training\n",
    "result = subprocess.run(train_cmd, cwd='/content/mlsp-cocktail-party-problem')\n",
    "print(f\"\\nTraining completed with exit code: {result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "monitoring"
   },
   "source": [
    "## 5. Monitor Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "check-outputs"
   },
   "outputs": [],
   "source": [
    "# List saved checkpoints\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "output_dir = Path('/content/mlsp-cocktail-party-problem/output/models/bilstm_colab')\n",
    "\n",
    "if output_dir.exists():\n",
    "    print(f\"Output directory: {output_dir}\\n\")\n",
    "    \n",
    "    # List subdirectories (run folders)\n",
    "    runs = sorted([d for d in output_dir.iterdir() if d.is_dir()])\n",
    "    \n",
    "    if runs:\n",
    "        latest_run = runs[-1]\n",
    "        print(f\"Latest run: {latest_run.name}\")\n",
    "        print(f\"\\nCheckpoints:\")\n",
    "        \n",
    "        checkpoints = sorted(latest_run.glob('*.pth'))\n",
    "        for ckpt in checkpoints:\n",
    "            size_mb = ckpt.stat().st_size / (1024 ** 2)\n",
    "            print(f\"  {ckpt.name} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "        # Display config\n",
    "        config_file = latest_run / 'config.json'\n",
    "        if config_file.exists():\n",
    "            print(f\"\\nConfig file: {config_file.name}\")\n",
    "            with open(config_file) as f:\n",
    "                config = json.load(f)\n",
    "                print(f\"Model parameters: {config.get('model', {})}\")\n",
    "                print(f\"Training parameters: {config.get('training', {})}\")\n",
    "else:\n",
    "    print(f\"Output directory not found: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "view-logs"
   },
   "outputs": [],
   "source": [
    "# View training logs (last 50 lines)\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path('/content/mlsp-cocktail-party-problem/output/models/bilstm_colab')\n",
    "runs = sorted([d for d in output_dir.iterdir() if d.is_dir()], key=lambda x: x.stat().st_mtime)\n",
    "\n",
    "if runs:\n",
    "    latest_run = runs[-1]\n",
    "    log_file = latest_run / 'training.log'\n",
    "    \n",
    "    if log_file.exists():\n",
    "        print(f\"Training log (last 50 lines):\\n\")\n",
    "        with open(log_file) as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines[-50:]:\n",
    "                print(line, end='')\n",
    "    else:\n",
    "        print(f\"No log file found at: {log_file}\")\n",
    "else:\n",
    "    print(\"No training runs found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-checkpoint"
   },
   "source": [
    "## 6. Download Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "download-model"
   },
   "outputs": [],
   "source": [
    "# Download trained model from Colab to local machine\n",
    "# This creates a zip file you can download\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path('/content/mlsp-cocktail-party-problem/output/models/bilstm_colab')\n",
    "runs = sorted([d for d in output_dir.iterdir() if d.is_dir()], key=lambda x: x.stat().st_mtime)\n",
    "\n",
    "if runs:\n",
    "    latest_run = runs[-1]\n",
    "    \n",
    "    # Create zip file\n",
    "    zip_path = '/content/bilstm_model_checkpoint.zip'\n",
    "    shutil.make_archive('/content/bilstm_model_checkpoint', 'zip', latest_run.parent, latest_run.name)\n",
    "    \n",
    "    # Get file size\n",
    "    size_gb = Path(zip_path).stat().st_size / (1024 ** 3)\n",
    "    print(f\"Model checkpoint saved: {zip_path}\")\n",
    "    print(f\"Size: {size_gb:.2f} GB\")\n",
    "    print(f\"\\nYou can download this file from Colab's file browser (left sidebar)\")\n",
    "else:\n",
    "    print(\"No trained model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference"
   },
   "source": [
    "## 7. Test Inference with Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inference-test"
   },
   "outputs": [],
   "source": [
    "# Test inference with trained model\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from src.models.bilstm import BiLSTMSeparator\n",
    "\n",
    "output_dir = Path('/content/mlsp-cocktail-party-problem/output/models/bilstm_colab')\n",
    "runs = sorted([d for d in output_dir.iterdir() if d.is_dir()], key=lambda x: x.stat().st_mtime)\n",
    "\n",
    "if runs:\n",
    "    latest_run = runs[-1]\n",
    "    checkpoint_path = latest_run / 'best_model.pth'\n",
    "    config_path = latest_run / 'config.json'\n",
    "    \n",
    "    if checkpoint_path.exists() and config_path.exists():\n",
    "        # Load config\n",
    "        with open(config_path) as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        model_config = config['model']\n",
    "        dataset_config = config['dataset']\n",
    "        \n",
    "        # Create model\n",
    "        model = BiLSTMSeparator(\n",
    "            num_sources=dataset_config['n_src'],\n",
    "            num_layers=model_config['num_layers'],\n",
    "            hidden_size=model_config['hidden_size'],\n",
    "            dropout=model_config['dropout'],\n",
    "            n_fft=model_config['n_fft'],\n",
    "            hop_length=model_config['hop_length']\n",
    "        )\n",
    "        \n",
    "        # Load checkpoint\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "        \n",
    "        print(f\"Model loaded successfully!\")\n",
    "        print(f\"Checkpoint: {checkpoint_path.name}\")\n",
    "        print(f\"\\nTraining info:\")\n",
    "        print(f\"  Epoch: {checkpoint['epoch']}\")\n",
    "        print(f\"  Best SI-SNR: {checkpoint['best_si_snr']:.4f} dB\")\n",
    "        \n",
    "        # Test inference\n",
    "        with torch.no_grad():\n",
    "            # Create dummy mixture (batch_size=1, 16000 samples = 1 second at 16kHz)\n",
    "            mixture = torch.randn(1, 16000)\n",
    "            separated = model(mixture)\n",
    "            \n",
    "            print(f\"\\nInference test successful!\")\n",
    "            print(f\"  Input shape: {mixture.shape}\")\n",
    "            print(f\"  Output shape: {separated.shape}\")\n",
    "            print(f\"  Expected: [batch=1, sources=2, time=16000]\")\n",
    "    else:\n",
    "        print(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "else:\n",
    "    print(\"No training runs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "resume-training"
   },
   "source": [
    "## 8. Resume Training from Checkpoint (Optional)\n",
    "\n",
    "If your training was interrupted, you can resume from the best checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "resume-train"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('/content/mlsp-cocktail-party-problem')\n",
    "\n",
    "# Find latest checkpoint\n",
    "output_dir = Path('output/models/bilstm_colab')\n",
    "runs = sorted([d for d in output_dir.iterdir() if d.is_dir()], key=lambda x: x.stat().st_mtime)\n",
    "\n",
    "if runs:\n",
    "    latest_run = runs[-1]\n",
    "    checkpoint_path = latest_run / 'best_model.pth'\n",
    "    \n",
    "    if checkpoint_path.exists():\n",
    "        # Resume training\n",
    "        train_cmd = [\n",
    "            'python', '-m', 'src.train.bilstm_train',\n",
    "            '--root-dir-data', 'data/Libri2Mix',\n",
    "            '--config-data', 'config/libri2mix_16k_2src.yaml',\n",
    "            '--config-model', 'config/bilstm_colab.yaml',\n",
    "            '--resume', str(checkpoint_path),\n",
    "            '--save-checkpoints',\n",
    "            '--save-every', '5',\n",
    "            '--log-level', 'INFO'\n",
    "        ]\n",
    "        \n",
    "        print(f\"Resuming training from: {checkpoint_path}\")\n",
    "        print(f\"Command: {' '.join(train_cmd)}\\n\")\n",
    "        \n",
    "        result = subprocess.run(train_cmd)\n",
    "        print(f\"\\nResumed training completed with exit code: {result.returncode}\")\n",
    "    else:\n",
    "        print(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "else:\n",
    "    print(\"No training runs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "notes"
   },
   "source": [
    "## Notes\n",
    "\n",
    "### GPU Memory Considerations\n",
    "- Colab T4 GPU: ~16GB VRAM\n",
    "- BiLSTM with hidden_size=512: Uses ~8-10GB with batch_size=16\n",
    "- If you get OOM errors, reduce:\n",
    "  - `hidden_size` from 512 to 256\n",
    "  - `num_layers` from 2 to 1\n",
    "  - Check dataloader batch sizes in config\n",
    "\n",
    "### Training Time\n",
    "- Each epoch: ~2-3 minutes (13,900 train samples)\n",
    "- 50 epochs: ~2-2.5 hours\n",
    "- Early stopping may trigger earlier\n",
    "\n",
    "### Resuming Training\n",
    "- Checkpoints are saved every 5 epochs + best model\n",
    "- Use cell 8 to resume from the best checkpoint\n",
    "- All training metadata is saved in `config.json`\n",
    "\n",
    "### Saving Results\n",
    "- Model checkpoints are in `output/models/bilstm_colab/<run_id>/`\n",
    "- Download the zip file from Colab's file browser\n",
    "- Or mount Google Drive to save directly to Drive\n",
    "\n",
    "### Troubleshooting\n",
    "- **LibriMix download fails**: Use existing dataset or mount Google Drive\n",
    "- **OOM errors**: Reduce hidden_size or batch size in config\n",
    "- **Slow training**: May indicate I/O bottleneck, consider caching to local SSD\n",
    "- **Session timeout**: Save checkpoints frequently, resume from latest"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "BiLSTM Source Separation Training",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
